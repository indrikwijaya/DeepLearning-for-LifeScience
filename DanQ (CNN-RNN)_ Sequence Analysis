{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DanQ (CNN-RNN): Sequence Analysis","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPHLfemSEY8qX9wtAvxIeh5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"picy9FUWvyDi","executionInfo":{"status":"ok","timestamp":1641376134542,"user_tz":-480,"elapsed":153316,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"e2ad5e5c-ece5-461e-b4d9-351baae6181f"},"source":["! pip install gdown\n","! gdown https://drive.google.com/u/0/uc?id=1wPj4M2a_fWqyV9HKUtycKd6dzvrgNeBb&export=download\n","! ls"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n","Downloading...\n","From: https://drive.google.com/u/0/uc?id=1wPj4M2a_fWqyV9HKUtycKd6dzvrgNeBb\n","To: /content/deepsea_data.tgz\n","100% 3.82G/3.82G [00:58<00:00, 65.3MB/s]\n","deepsea_data.tgz  sample_data\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sjCpJDcAwLAK","executionInfo":{"status":"ok","timestamp":1641376215202,"user_tz":-480,"elapsed":80684,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"f253dd26-ee46-49ad-feb1-251900dcba5b"},"source":["! tar -xvzf deepsea_data.tgz"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["deepsea_data/\n","deepsea_data/test.mat\n","deepsea_data/train.mat\n","deepsea_data/valid.mat\n"]}]},{"cell_type":"markdown","metadata":{"id":"uE5gBrT_0pau"},"source":["[Link for paper](https://www.ncbi.nlm.nih.gov/pubmed/27084946)\n","\n","[Link for repo](https://github.com/liyu95/Deep_learning_examples/tree/master/2.CNN_RNN_sequence_analysis)\n","\n","- Use CNN & RNN to predict the funtionality of non-coding DNA sequences\n","- Data from [DeepSEA](https://www.nature.com/articles/nmeth.3547)\n","- The human GRCh37 reference genome was segmented into non-overlapping 200-bp bins\n","- Input: 1000-bp DNA sequences which are centered on the 200-bp bins\n","- Label: generated by collecting profiles from ENCODE and Roadmap Epigenomic data releases, which resulted in binary vectory for each sequence (690 TF binding profiles, 125 DNase I-hypersensitive profiles & 104 histone-mark profiles)\n","- To encode the DNA sequence string into a mathematical form which can be fed to the model, we use the one-hot encoding \n","- In terms of the model, because for DNA sequences, not only do the specific motifs matter, but also the interaction between the upstream & downstream motifs also play important roles in determining the sequence functionality, we combine CNN & RNN, stacking a bi-diretional LSTM layer on top of 1D convolutional layers\n","\n","### Model details\n","\n","<img src = 'https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/nar/44/11/10.1093_nar_gkw226/4/m_gkw226fig1.jpeg?Expires=1637004860&Signature=xABS9hsRaXXN4di7eyHay2EtjrtDTZFSzoqfrP4f8Y~0wCLcG2gs9zfKx4iS-ahggRQczH6VV9Ya0jaiuESntY-4s9egF1YWQrGlV7Dkyb8Bnb9NhruvxGcNjcgvz~cNk0Cji~ILXGVq97howKPbF1d1nlcH-vlRGgDj8ZCOmab0LBK0arWhBFnVr0llpZ3hF0aAW-o8GwZTJLwl5KsReZMnzg3x6wSefmFqNfkKRxPu07MtvZISZTUyR0j6l-sGqcw4YbFdT63BNxbHcAIbasSpeOvFUx9GsBSJbD8x0Wz-jJ0xkd7AJtonYYeg0rSO~fxINhb0vGNgL68dIKvokA__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA'>\n","\n","- an input sequence is first one hot encoded into a 4-row bit matrix\n","- a convolution layer w/ rectifier activation acts as a motif scanner across the input matrix to produce an output matrix w/ a row for each convolution kernel and a column for each position in the input (minus the width if the kernel)\n","- Max pooling reduces the size of the output matrix along the spatial axis, preserving the number of channels\n","- The subsequent BLSTM later considers the orientations and spatial distances between the motifs\n","-> rationale: motifs can follow a regulatory grammar governed by physical constraints that dictate the *in vivo* spatial arrangements and frequencies of combinations of motifs, a feature associated with tissue-specific functional elements such as enhancers.\n","- BLSTM outputs are flattened into a layer as inputs to a fully connected layer of ReLU units\n","- Final layer: performs a sigmoid non-linear transformation to a vector that serves as a probability predictions of the epigenetic marks to be compared via a loss function to the true target vector\n","\n","The paper also shows that the convolution kernels learned by the model can be converted to motifs, many of which significantly match known motifs. As such, it expects the model to provide novel insights into non-coding genomic regions and contribute to understanding the potential functions of complex disease-or trait-associated genetic variants"]},{"cell_type":"code","metadata":{"id":"io0vSIeS3gl4","executionInfo":{"status":"ok","timestamp":1641376223319,"user_tz":-480,"elapsed":8127,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}}},"source":["import numpy as np\n","import h5py\n","import scipy.io\n","np.random.seed(1337) # for reproducibility\n","\n","import keras\n","import tensorflow as tf\n","from keras.preprocessing import sequence\n","from tensorflow.keras.optimizers import RMSprop\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Dropout, Activation, Flatten\n","from keras.layers.convolutional import Convolution1D, MaxPooling1D\n","from keras.regularizers import l2\n","from keras.constraints import maxnorm\n","from keras.layers.recurrent import LSTM, GRU\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.layers import Bidirectional\n","\n","import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '1'"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sld_X97F-cDa"},"source":["## Load data"]},{"cell_type":"code","metadata":{"id":"-92g4VGG8DGw"},"source":["trainmat = h5py.File('deepsea_data/train.mat')\n","validmat = scipy.io.loadmat('deepsea_data/valid.mat')\n","testmat = scipy.io.loadmat('deepsea_data/test.mat')\n","\n","X_train = np.transpose(np.array(trainmat['trainxdata']), axes=(2, 0, 1))\n","y_train = np.array(trainmat['traindata']).T"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Session crashed due to insufficient RAM!"],"metadata":{"id":"VeUImibo-r_w"}},{"cell_type":"code","source":[""],"metadata":{"id":"eD2IujaOp5zi"},"execution_count":null,"outputs":[]}]}